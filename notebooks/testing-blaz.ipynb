{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from normalizing_flows.flows import Flow, PrincipalManifoldFlow\n",
    "from normalizing_flows.bijections import RealNVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from test.shapes import *\n",
    "\n",
    "sys.path.remove('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Swirl')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_points = 10\n",
    "data_swirl = swirl(radius=1, angle=0, num_points=num_points, noise_std=0.03, seed=0)\n",
    "\n",
    "# plot data\n",
    "plt.figure()\n",
    "plt.scatter(data_swirl[0], data_swirl[1], s=1)\n",
    "plt.title('Swirl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "data_tensor = torch.tensor(np.stack(data_swirl, axis=1)).float()  # Create a tensor from the data\n",
    "n_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(0)\n",
    "# normal_flow = Flow(RealNVP(n_dim, n_layers=10), record_Ihat_P=True, record_log_px=True)\n",
    "# normal_flow.fit(data_tensor, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.tensor([[0.5, 0.5], [0.5, 0.5], [0.5, 0.5], [0.5, 0.5]]).float()\n",
    "# result = torch.vmap(normal_flow.bijection.forward, chunk_size=1)(x.unsqueeze(1))\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NF_log_px = normal_flow.get_log_px()\n",
    "# NF_Ihat_P = normal_flow.get_Ihat_P()\n",
    "\n",
    "# # print all\n",
    "# print(\"NF_log_px: \", len(NF_log_px))\n",
    "# print(\"NF log_px average: \", torch.mean(NF_log_px))\n",
    "# print(\"NF_Ihat_P: \", len(NF_Ihat_P))\n",
    "# print(\"NF Ihat_P average: \", torch.mean(NF_Ihat_P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting Principal Manifold Flow:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  torch.Size([2])\n",
      "x:  GradTrackingTensor(lvl=2, value=\n",
      "    BatchedTensor(lvl=1, bdim=0, value=\n",
      "        tensor([[ 0.0672, -0.2531],\n",
      "                [ 1.0529, -0.0293],\n",
      "                [ 0.4706, -0.0045],\n",
      "                [ 0.0560,  0.0123],\n",
      "                [-0.0120,  0.2785],\n",
      "                [-0.0672, -0.7531],\n",
      "                [-0.4706, -0.0045],\n",
      "                [-1.0560,  0.0123],\n",
      "                [ 0.0120,  0.7785],\n",
      "                [-0.0529, -0.0293]])\n",
      "    )\n",
      ")\n",
      "x.shape (inside bijective composition):  GradTrackingTensor(lvl=2, value=\n",
      "    BatchedTensor(lvl=1, bdim=0, value=\n",
      "        tensor([[[ 0.0672, -0.2531]],\n",
      "\n",
      "                [[ 1.0529, -0.0293]],\n",
      "\n",
      "                [[ 0.4706, -0.0045]],\n",
      "\n",
      "                [[ 0.0560,  0.0123]],\n",
      "\n",
      "                [[-0.0120,  0.2785]],\n",
      "\n",
      "                [[-0.0672, -0.7531]],\n",
      "\n",
      "                [[-0.4706, -0.0045]],\n",
      "\n",
      "                [[-1.0560,  0.0123]],\n",
      "\n",
      "                [[ 0.0120,  0.7785]],\n",
      "\n",
      "                [[-0.0529, -0.0293]]])\n",
      "    )\n",
      ")\n",
      "ElementwiseAffine(\n",
      "  (transformer): Affine()\n",
      ")\n",
      "h:  GradTrackingTensor(lvl=2, value=\n",
      "    tensor([[[ 1.5410, -0.2934],\n",
      "             [-2.1788,  0.5684]]], grad_fn=<RepeatBackward0>)\n",
      ")\n",
      "log_det_layer.shape:  GradTrackingTensor(lvl=2, value=\n",
      "    tensor([-0.3175], grad_fn=<SumBackward1>)\n",
      ")\n",
      "log_det.shape:  GradTrackingTensor(lvl=2, value=\n",
      "    tensor([0.])\n",
      ")\n",
      "ReversePermutation(\n",
      "  (matrix): PermutationMatrix()\n",
      ")\n",
      "log_det_layer.shape:  GradTrackingTensor(lvl=2, value=\n",
      "    tensor([0.])\n",
      ")\n",
      "log_det.shape:  GradTrackingTensor(lvl=2, value=\n",
      "    tensor([-0.3175], grad_fn=<AddBackward0>)\n",
      ")\n",
      "AffineCoupling(\n",
      "  (conditioner_transform): FeedForward(\n",
      "    (context_combiner): Bypass()\n",
      "    (sequential): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=4, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=4, out_features=2, bias=True)\n",
      "      (3): Unflatten(dim=-1, unflattened_size=torch.Size([1, 2]))\n",
      "    )\n",
      "  )\n",
      "  (transformer): Affine()\n",
      ")\n",
      "h:  GradTrackingTensor(lvl=2, value=\n",
      "    BatchedTensor(lvl=1, bdim=0, value=\n",
      "        tensor([[[[0.0786, 0.2856]]],\n",
      "\n",
      "\n",
      "                [[[0.0792, 0.2939]]],\n",
      "\n",
      "\n",
      "                [[[0.0792, 0.2949]]],\n",
      "\n",
      "\n",
      "                [[[0.0793, 0.2955]]],\n",
      "\n",
      "\n",
      "                [[[0.0803, 0.3053]]],\n",
      "\n",
      "\n",
      "                [[[0.0775, 0.2673]]],\n",
      "\n",
      "\n",
      "                [[[0.0792, 0.2949]]],\n",
      "\n",
      "\n",
      "                [[[0.0793, 0.2955]]],\n",
      "\n",
      "\n",
      "                [[[0.0836, 0.3234]]],\n",
      "\n",
      "\n",
      "                [[[0.0792, 0.2939]]]], grad_fn=<ViewBackward0>)\n",
      "    )\n",
      ")\n",
      "log_det_layer.shape:  GradTrackingTensor(lvl=2, value=\n",
      "    BatchedTensor(lvl=1, bdim=0, value=\n",
      "        tensor([[0.0393],\n",
      "                [0.0395],\n",
      "                [0.0396],\n",
      "                [0.0396],\n",
      "                [0.0401],\n",
      "                [0.0387],\n",
      "                [0.0396],\n",
      "                [0.0396],\n",
      "                [0.0418],\n",
      "                [0.0395]], grad_fn=<SumBackward1>)\n",
      "    )\n",
      ")\n",
      "log_det.shape:  GradTrackingTensor(lvl=2, value=\n",
      "    tensor([-0.3175], grad_fn=<AddBackward0>)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1] doesn't match the broadcast shape [10, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m PM_flow \u001b[38;5;241m=\u001b[39m PrincipalManifoldFlow(RealNVP(n_dim, n_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m), record_Ihat_P\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, record_log_px\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munbiased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mPM_flow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/normalizing-flows-fork/normalizing_flows/flows.py:832\u001b[0m, in \u001b[0;36mPrincipalManifoldFlow.fit\u001b[0;34m(self, x_train, n_epochs, lr, batch_size, shuffle, show_progress, w_train, context_train, x_val, w_val, context_val, keep_best_weights, early_stopping, early_stopping_threshold)\u001b[0m\n\u001b[1;32m    830\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_Ihat_P \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_log_px:\n\u001b[0;32m--> 832\u001b[0m     train_loss, Ihat_p, log_px \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_batch_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m     Ihat_P_epoch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((Ihat_P_epoch, Ihat_p))\n\u001b[1;32m    834\u001b[0m     log_px_epoch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((log_px_epoch, log_px))\n",
      "File \u001b[0;32m~/Documents/GitHub/normalizing-flows-fork/normalizing_flows/flows.py:811\u001b[0m, in \u001b[0;36mPrincipalManifoldFlow.fit.<locals>.compute_batch_loss\u001b[0;34m(batch_, reduction)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munbiased\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_Ihat_P \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_log_px:\n\u001b[0;32m--> 811\u001b[0m         batch_objective, Ihat_p, log_px \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPF_objective_unbiased\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m batch_objective, Ihat_p, log_px\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/GitHub/normalizing-flows-fork/normalizing_flows/flows.py:680\u001b[0m, in \u001b[0;36mPrincipalManifoldFlow.PF_objective_unbiased\u001b[0;34m(self, x, reduction, random_seed, context)\u001b[0m\n\u001b[1;32m    676\u001b[0m     objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mlog_px \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m Ihat_P\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m objective, Ihat_P, log_px\n\u001b[0;32m--> 680\u001b[0m objective, Ihat_P, log_px \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_unbathced\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;66;03m# objective, Ihat_P, log_px = objective_unbathced(x)\u001b[39;00m\n\u001b[1;32m    682\u001b[0m objective \u001b[38;5;241m=\u001b[39m reduction(objective)\n",
      "File \u001b[0;32m~/Documents/GitHub/normalizing-flows-fork/.conda/lib/python3.10/site-packages/torch/_functorch/apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/normalizing-flows-fork/.conda/lib/python3.10/site-packages/torch/_functorch/vmap.py:266\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[1;32m    263\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/normalizing-flows-fork/.conda/lib/python3.10/site-packages/torch/_functorch/vmap.py:38\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/normalizing-flows-fork/.conda/lib/python3.10/site-packages/torch/_functorch/vmap.py:379\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 379\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/GitHub/normalizing-flows-fork/normalizing_flows/flows.py:663\u001b[0m, in \u001b[0;36mPrincipalManifoldFlow.PF_objective_unbiased.<locals>.objective_unbathced\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    660\u001b[0m     log_pz \u001b[38;5;241m=\u001b[39m log_pz\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m z, (z, log_det, log_pz)\n\u001b[0;32m--> 663\u001b[0m G, (z, log_det, log_pz) \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjacrev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapply_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;66;03m# log_px = log_pz + 0.5*log_det # This was our version\u001b[39;00m\n\u001b[1;32m    665\u001b[0m log_px \u001b[38;5;241m=\u001b[39m log_pz \u001b[38;5;241m+\u001b[39m log_det \u001b[38;5;66;03m# taken from author's code\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/normalizing-flows-fork/.conda/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:492\u001b[0m, in \u001b[0;36mjacrev.<locals>.wrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    491\u001b[0m     error_if_complex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacrev\u001b[39m\u001b[38;5;124m\"\u001b[39m, args, is_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 492\u001b[0m     vjp_out \u001b[38;5;241m=\u001b[39m \u001b[43m_vjp_with_argnums\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_aux\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m    494\u001b[0m         output, vjp_fn, aux \u001b[38;5;241m=\u001b[39m vjp_out\n",
      "File \u001b[0;32m~/Documents/GitHub/normalizing-flows-fork/.conda/lib/python3.10/site-packages/torch/_functorch/vmap.py:38\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/normalizing-flows-fork/.conda/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:294\u001b[0m, in \u001b[0;36m_vjp_with_argnums\u001b[0;34m(func, argnums, has_aux, *primals)\u001b[0m\n\u001b[1;32m    292\u001b[0m     diff_primals \u001b[38;5;241m=\u001b[39m _slice_argnums(primals, argnums, as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    293\u001b[0m     tree_map_(partial(_create_differentiable, level\u001b[38;5;241m=\u001b[39mlevel), diff_primals)\n\u001b[0;32m--> 294\u001b[0m primals_out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(primals_out, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(primals_out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/GitHub/normalizing-flows-fork/normalizing_flows/flows.py:656\u001b[0m, in \u001b[0;36mPrincipalManifoldFlow.PF_objective_unbiased.<locals>.objective_unbathced.<locals>.apply_func\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx: \u001b[39m\u001b[38;5;124m\"\u001b[39m, x)\n\u001b[0;32m--> 656\u001b[0m z, log_det \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbijection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m log_pz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_log_prob(z)\n\u001b[1;32m    658\u001b[0m z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/normalizing-flows-fork/normalizing_flows/bijections/base.py:108\u001b[0m, in \u001b[0;36mBijectiveComposition.forward\u001b[0;34m(self, x, context, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_det_layer.shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m, log_det_layer)\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_det.shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m, log_det)\n\u001b[0;32m--> 108\u001b[0m     log_det \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m log_det_layer\n\u001b[1;32m    109\u001b[0m z \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z, log_det\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [1] doesn't match the broadcast shape [10, 1]"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "PM_flow = PrincipalManifoldFlow(RealNVP(n_dim, n_layers=10), record_Ihat_P=True, record_log_px=True, debug=False, objective=\"unbiased\")\n",
    "PM_flow.fit(data_tensor, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
